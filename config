#提取文件名
#java_file=${java_wget##*\/}
hadoop_file=${hadoop_wget##*\/}
hive_file=${hive_wget##*\/}
zookeeper_file=${zookeeper_wget##*\/}
hbase_file=${hbase_wget##*\/}
spark_file=${spark_wget##*\/}
kafka_file=${kafka_wget##*\/}
tez_file=${tez_wget##*\/}
sqoop_file=${sqoop_wget##*\/}
flume_file=${flume_wget##*\/}
storm_file=${storm_wget##*\/}
scala_file=${scala_wget##*\/}
flink_file=${flink_wget##*\/}

#提取软件名
#java_name=${java_file%\.*}
scala_name=${scala_file%\.*}
spark_name=${spark_file%\.*}
kafka_name=${kafka_file%\.*}

hadoop_name=${hadoop_file%\.tar\.gz}
hive_name=${hive_file%\.tar\.gz}
zookeeper_name=${zookeeper_file%\.tar\.gz}
hbase_name=${hbase_file%\-bin*}

tez_name=${tez_file%\.tar\.gz}
sqoop_name=${sqoop_file%\.tar\.gz}
flume_name=${flume_file%\.tar\.gz}
storm_name=${storm_file%\.tar\.gz}

flink_name=${flink_file%\-bin*}

localip=`ifconfig wlo1 | grep 'inet ' | awk '{print $2}'`

#集群节点hostname
master=hdp-master
slave1=hdp-slave1
slave2=hdp-slave2

#工作用户名
hadoopuser=hadoop

#整体工作目录
workdir=/home/${hadoopuser}/data

#zookeeper数据目录
zoodatadir=${workdir}/zookeeper/data
zoodatalogdir=${workdir}/zookeeper/datalog


#hadoop数据目录
htmpdir=${workdir}/hadoop/data/tmp
namedir=${workdir}/hadoop/data/namenode
datadir=${workdir}/hadoop/data/datanode

#hbase数据目录
hbasetmpdir=${workdir}/hbase/data

#kafka_logs目录
kafka_logsdir=${workdir}/kafka/logsdir
#JAVA_HOME
java_home=/usr/lib/jvm/default-jvm
